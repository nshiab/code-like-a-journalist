---
title: Analyse simple de donn√©es et intelligence artificielle ü§ñ
description: Dans ce tutoriel, nous utilisons l'IA (plus pr√©cis√©ment les grands mod√®les linguistiques comme ChatGPT, Gemini et Claude) pour nous aider √† analyser des donn√©es.
---

import { Callout } from "nextra/components";
import { NoticeIntro, NoticeEnd } from "../../../components/Notices.jsx";

# Analyse de donn√©es et intelligence artificielle ü§ñ

Bienvenue dans ce nouveau projet o√π nous utiliserons l'IA (plus pr√©cis√©ment, les grands mod√®les linguistiques comme ChatGPT, Gemini et Claude) pour nous aider √† analyser des donn√©es ! Ces mod√®les sont remarquablement efficaces pour extraire, reformater, nettoyer et cat√©goriser des donn√©es.

En mars 2025, j'ai assist√© √† une excellente session √† [NICAR](https://www.ire.org/training/conferences/nicar-2025/) pr√©sent√©e par [Ben Welsh](https://github.com/palewire) et [Derek Willis](https://thescoop.org/about/). Ils nous ont montr√© comment cat√©goriser des demandes de remboursement √† l'aide de ces outils fascinants.

[Leur projet](https://palewi.re/docs/first-llm-classifier/) (en Python) a √©t√© une r√©v√©lation. J'ai donc d√©cid√© d'impl√©menter de nouvelles m√©thodes dans la biblioth√®que Simple Data Analysis (SDA) ([donnez-lui une ‚≠ê](https://github.com/nshiab/simple-data-analysis) !) pour tirer le meilleur parti des LLM. Je vais vous montrer comment utiliser ces m√©thodes avec une cl√© API Google AI Studio, mais elles fonctionnent √©galement avec Vertex AI et Ollama.

Ben a gentiment accept√© que je reproduise son tutoriel, mais cette fois en TypeScript ! Nous utiliserons Deno et VS Code. Consultez la le√ßon [Installation](/first-steps/setup) si n√©cessaire. Cependant, vous pouvez le faire avec l'engin d'ex√©cution JS/TS et l'√©diteur de code de votre choix !

Si vous √™tes bloqu√©, il pourrait √™tre utile de revoir les le√ßons pr√©c√©dentes expliquant les bases de SDA :
- [Donn√©es tabulaires](/simple-data-analysis/tabular-data)
- [Donn√©es g√©ospatiales](/simple-data-analysis/geospatial-data)
- [Visualisation des donn√©es](/simple-data-analysis/dataviz)

C'est parti pour le code !

<NoticeIntro lang="fr" />

## Configuration

Pour configurer tout ce dont nous avons besoin, utilisons [setup-sda](https://jsr.io/@nshiab/setup-sda) comme dans les le√ßons pr√©c√©dentes.

Cr√©ez un nouveau dossier, ouvrez-le avec VS Code et ex√©cutez : `deno -A jsr:@nshiab/setup-sda`

![Une capture d'√©cran de VS Code apr√®s l'ex√©cution de setup-sda.](/assets/simple-data-analysis/sda-and-ai/setup.png)

## Obtenir une cl√© API

Dans cette le√ßon, nous allons utiliser les LLM de Google. Pour interagir avec eux via notre code, nous avons besoin d'une cl√© API. Rendez-vous sur [Google AI Studio](https://aistudio.google.com/), cr√©ez un compte si vous n'en avez pas d√©j√† un, et cliquez sur `Obtenir une cl√© API`.

![Une capture d'√©cran de Google AI Studio.](/assets/simple-data-analysis/sda-and-ai/google-ai-studio.png)

Cliquez ensuite sur `Cr√©er une cl√© API`.

Suivez les √©tapes sugg√©r√©es. Si on vous demande d'utiliser un projet Google Cloud, s√©lectionnez Gemini si disponible ; sinon, cr√©ez-en un nouveau.

![Une capture d'√©cran de Google AI Studio.](/assets/simple-data-analysis/sda-and-ai/create-key.png)

Une fois que vous avez copi√© votre nouvelle cl√© API, cr√©ez un nouveau fichier `.env` dans votre projet et collez-la-y. Ajoutez √©galement le mod√®le que nous utiliserons, qui est `gemini-2.0-flash-lite`.

```txt filename=".env" showLineNumbers
AI_KEY=your_api_key_here
AI_MODEL=gemini-2.0-flash-lite
```

`.env` est un fichier que nous utilisons habituellement pour les **variables d'environnement**, qui sont souvent des identifiants qui ne doivent pas √™tre partag√©s. Lorsque vous configurez tout avec `setup-sda`, ce fichier est automatiquement ajout√© √† `.gitignore`, il ne sera donc pas commit√© par Git et ne sera pas pouss√© sur GitHub.

![Variables d'environnement dans VS Code.](/assets/simple-data-analysis/sda-and-ai/env.png)

Maintenant, il nous suffit de charger ces variables en m√©moire.

Installez la biblioth√®que `@std/dotenv` de l'√©quipe Deno en ex√©cutant `deno add jsr:@std/dotenv`.

Ensuite, ajoutez `import "@std/dotenv/load";` en haut de votre fichier `sda/main.ts`. Maintenant, chaque fois que vous ex√©cuterez ce code, Deno chargera automatiquement les variables de votre fichier `.env` !

Et nous sommes pr√™ts √† d√©coller ! üöÄ

![Une capture d'√©cran montrant comment charger les variables d'environnement.](/assets/simple-data-analysis/sda-and-ai/load-env.png)

## √Ä propos de cette API...

Avant d'ex√©cuter du code, il y a quelque chose que je veux vous montrer.

Dans Google AI Studio, apr√®s avoir cliqu√© sur `Obtenir une cl√© API`, vous avez acc√®s √† votre `Facturation de votre plan API`. S√©lectionnez le mod√®le que nous allons utiliser : `Gemini 2.0 Flash Lite`.

L√†, vous verrez que vous avez un compte gratuit qui vous permet de faire 30 requ√™tes par minute avec ce mod√®le (cela a peut-√™tre chang√© depuis que j'ai √©crit ceci).

Et vous remarquerez √©galement que... les donn√©es que vous allez envoyer seront utilis√©es par Google ! Alors, soyez tr√®s prudent : **n'envoyez pas de donn√©es sensibles via cette API !**

Comme vous le savez peut-√™tre d√©j√†, rien n'est vraiment gratuit dans la vie... ü•≤

Si vous avez un compte pro ou entreprise, ils d√©clarent qu'ils n'utiliseront pas vos donn√©es pour am√©liorer leurs produits. Mais si vous avez besoin d'une confidentialit√© totale, je vous montrerai √† la fin comment utiliser Ollama pour ex√©cuter des mod√®les localement sur votre machine.

![Facturation du plan Google AI.](/assets/simple-data-analysis/sda-and-ai/plan-billing.png)

## Les donn√©es

L'objectif du projet est de cat√©goriser des demandes de remboursement. Nous allons utiliser les donn√©es CSV du tutoriel de Ben. [Elles sont h√©berg√©es sur GitHub](https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv) et contiennent 250 lignes.

Ben a manuellement cat√©goris√© la colonne `payee`. Nous demanderons √† notre mod√®le de faire le m√™me exercice, puis nous comparerons les r√©sultats humains et ceux de l'IA.

![Les donn√©es d'exemple.](/assets/simple-data-analysis/sda-and-ai/sample-data.png)

Pour r√©cup√©rer les donn√©es, nous cr√©ons une nouvelle table `data` et mettons en cache les r√©sultats de `loadData`, qui r√©cup√®re les donn√©es de GitHub. Comme les donn√©es ne changeront pas, la mise en cache est logique. Elles seront stock√©es localement dans le dossier `.sda-cache`. Lorsque vous configurez tout avec `setup-sda`, ce dossier cach√© est ajout√© √† votre `.gitignore`.

Nous affichons √©galement la table dans le terminal.

Pour ex√©cuter ce code et le surveiller, ex√©cutez `deno task sda` dans votre terminal. √Ä chaque fois que nous allons modifier le code et le sauvegarder, il sera automatiquement ex√©cut√©. Pratique!

```ts showLineNumbers filename="sda/main.ts" {6-13}
import "@std/dotenv/load";
import { SimpleDB } from "@nshiab/simple-data-analysis";

const sdb = new SimpleDB();

const data = sdb.newTable("data");
await data.cache(async () => {
  await data.loadData(
    "https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv",
  );
});

await data.logTable();

await sdb.done();
```

![Chargement des donn√©es depuis GitHub.](/assets/simple-data-analysis/sda-and-ai/loading-data.png)
<Callout type="info" emoji="üí°">
   Si vous voulez supprimer le cache, vous pouvez supprimer manuellement `.sda-cache` ou ex√©cuter `deno task clean` dans votre terminal.
</Callout>

## Envoi de donn√©es au mod√®le

Pour envoyer des donn√©es et des instructions au mod√®le, nous devons utiliser la m√©thode `aiRowByRow` sur notre table. Si vous √™tes curieux, vous trouverez [la documentation ici](https://jsr.io/@nshiab/simple-data-analysis/doc/~/SimpleTable.prototype.aiRowByRow).

Son utilisation est assez simple :
- Tout d'abord, passez la colonne contenant les donn√©es que vous souhaitez envoyer √† l'IA (ici, c'est `payee`).
- Ensuite, indiquez le nom de la nouvelle colonne qui sera cr√©√©e pour stocker les r√©sultats de l'IA (ici, nous la nommons `categoryAI`).
- Et enfin, tapez votre prompt. Ici, nous demandons au LLM de cat√©goriser le `payee`.

Le quatri√®me argument est facultatif. C'est un objet avec quelques options :
- `rateLimitPerMinute` garantira que nous respectons notre quota d'API. Si nous envoyons des requ√™tes trop rapidement, la m√©thode attendra la dur√©e n√©cessaire pour √©viter que les requ√™tes ne soient rejet√©es.
- `verbose` affichera des informations suppl√©mentaires dans le terminal pendant le traitement des donn√©es.

```ts showLineNumbers filename="sda/main.ts" {13-21}
import "@std/dotenv/load";
import { SimpleDB } from "@nshiab/simple-data-analysis";

const sdb = new SimpleDB();

const data = sdb.newTable("data");
await data.cache(async () => {
  await data.loadData(
    "https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv",
  );
});

await data.aiRowByRow(
  "payee",
  "categoryAI",
  `Categorize the payee into one of the following categories: Restaurant, Bar, Hotel or Other. `,
  {
    rateLimitPerMinute: 30,
    verbose: true,
  },
);

await data.logTable();

await sdb.done();
```

Si vous ex√©cutez ce code, vous verrez votre prompt ainsi que des instructions suppl√©mentaires ajout√©es par la m√©thode.

L'option `verbose` ajoute des informations suppl√©mentaires utiles. Les **tokens** repr√©sentent la quantit√© d'informations envoy√©es et re√ßues par l'IA. Sur cette base, la m√©thode vous donne une estimation du co√ªt de la requ√™te si vous avez un compte avec paiement √† l'utilisation.

Actuellement, les donn√©es sont classifi√©es par le mod√®le d'IA, mais... c'est un peu lent.

Parce que nous avons 250 lignes de donn√©es, et que nous ne pouvons envoyer que 30 requ√™tes par minute, classer l'ensemble des donn√©es prendra... plus de 8 minutes !

Nous pouvons s√ªrement acc√©l√©rer cela !

![Envoi d'une ligne √† la fois.](/assets/simple-data-analysis/sda-and-ai/one-row-at-the-time.png)

## Acc√©l√©rer le processus

### Lots

Au lieu d'envoyer une ligne √† la fois, nous pourrions en envoyer un lot !

Dans le code ci-dessous, nous utilisons l'option `batchSize` pour envoyer 10 lignes √† la fois. Maintenant, le traitement de l'ensemble des donn√©es prend moins d'une minute !

C'est g√©nial, mais nous pouvons pousser cela un peu plus loin...

```ts showLineNumbers filename="sda/main.ts" {18}
import "@std/dotenv/load";
import { SimpleDB } from "@nshiab/simple-data-analysis";

const sdb = new SimpleDB();

const data = sdb.newTable("data");
await data.cache(async () => {
  await data.loadData(
    "https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv",
  );
});

await data.aiRowByRow(
  "payee",
  "categoryAI",
  `Categorize the payee into one of the following categories: Restaurant, Bar, Hotel or Other. `,
  {
    batchSize: 10,
    rateLimitPerMinute: 30,
    verbose: true,
  },
);

await data.logTable();

await sdb.done();
```

![Envoi de lots de donn√©es.](/assets/simple-data-analysis/sda-and-ai/batches.png)

### Concurrence

L'une des nombreuses fonctionnalit√©s formidables de TypeScript et JavaScript est la **concurrence**. Au lieu de faire une seule requ√™te √† l'API √† la fois, vous en envoyez plusieurs simultan√©ment et attendez ensuite les r√©sultats en parall√®le.

Tirer parti de cette fonctionnalit√© du langage peut acc√©l√©rer l'ex√©cution de notre code !

Puisque nous avons 250 lignes de donn√©es, nous pourrions envoyer des lots de 17 lignes avec 15 requ√™tes concurrentes pour traiter toutes nos donn√©es en moins de... 2 secondes !

Ces 15 requ√™tes nous maintiennent en dessous de la limite de quota de 30, ce qui est important.

Un conseil : pour ex√©cuter ce code, assurez-vous de n'avoir pas envoy√© de requ√™tes depuis au moins une minute ; sinon, vous pourriez atteindre la limite de quota du plan gratuit.

```ts showLineNumbers filename="sda/main.ts" /{ logDuration: true }/ {18-19}
import "@std/dotenv/load";
import { SimpleDB } from "@nshiab/simple-data-analysis";

const sdb = new SimpleDB({ logDuration: true });

const data = sdb.newTable("data");
await data.cache(async () => {
  await data.loadData(
    "https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv",
  );
});

await data.aiRowByRow(
  "payee",
  "categoryAI",
  `Categorize the payee into one of the following categories: Restaurant, Bar, Hotel or Other. `,
  {
    batchSize: 17,
    concurrent: 15,
    rateLimitPerMinute: 30,
    verbose: true,
  },
);

await data.logTable();

await sdb.done();
```

![Envoi de requ√™tes concurrentes.](/assets/simple-data-analysis/sda-and-ai/concurrency.png)

### Mise en cache

Il y a une derni√®re astuce que nous pouvons utiliser pour rendre notre code plus efficace : le **mise en cache**.

Nous pourrions stocker les r√©sultats envoy√©s par l'IA dans des fichiers localement. Si nous r√©ex√©cutons notre code et que le prompt/les donn√©es n'ont pas chang√©, nous pourrions utiliser ce que nous avons stock√© sur notre machine au lieu d'attendre √† nouveau le mod√®le d'IA.

C'est exactement ce que l'option `cache` vous permet de faire.

```ts showLineNumbers filename="sda/main.ts" {20}
import "@std/dotenv/load";
import { SimpleDB } from "@nshiab/simple-data-analysis";

const sdb = new SimpleDB({ logDuration: true });

const data = sdb.newTable("data");
await data.cache(async () => {
  await data.loadData(
    "https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv",
  );
});

await data.aiRowByRow(
  "payee",
  "categoryAI",
  `Categorize the payee into one of the following categories: Restaurant, Bar, Hotel or Other. `,
  {
    batchSize: 17,
    concurrent: 15,
    cache: true,
    rateLimitPerMinute: 30,
    verbose: true,
  },
);

await data.logTable();

await sdb.done();
```

Si vous ex√©cutez ce code, vous remarquerez un nouveau dossier cach√© `.journalism-cache`. Les fichiers qu'il contient sont des fichiers JSON stockant les r√©ponses de l'IA. Il fonctionne comme le dossier `.sda-cache` pr√©c√©dent, mais il est cr√©√© par la fonction [`askAI`](https://jsr.io/@nshiab/journalism/doc/~/askAI) de ma biblioth√®que [`journalism`](https://jsr.io/@nshiab/journalism), que la m√©thode `aiRowByRow` utilise pour interagir avec le mod√®le d'IA.

Lors de la premi√®re ex√©cution, les requ√™tes sont faites et le script prend autant de temps d'ex√©cution qu'auparavant.

![Mise en cache des donn√©es.](/assets/simple-data-analysis/sda-and-ai/caching.png)

Mais si vous r√©ex√©cutez ce script (`CTRL` + `S` dans `main.ts` devrait faire l'affaire), il est maintenant beaucoup plus rapide ! Il ne prend que quelques millisecondes ! Au lieu de faire les requ√™tes, le code r√©cup√®re les donn√©es stock√©es sur votre machine.

Bien s√ªr, si vous modifiez le prompt ou les donn√©es envoy√©es au mod√®le, la m√©thode saura qu'elle doit faire de nouvelles requ√™tes et stocker de nouveaux r√©sultats. Mais si vous ne touchez pas aux arguments `aiRowByRow` modifiant les requ√™tes, vous pouvez travailler en toute s√©curit√© sur d'autres choses sans √©puiser vos quotas d'API et √† pleine vitesse !

![R√©cup√©ration depuis le cache.](/assets/simple-data-analysis/sda-and-ai/retrieving-from-cache.png)
<Callout type="info" emoji="üí°">
   Si vous voulez supprimer le cache, vous pouvez supprimer manuellement `.journalism-cache` ou ex√©cuter `deno task clean` dans votre terminal.
</Callout>

## Tester les r√©sultats

### Tests

Bien qu'ils s'am√©liorent √† un rythme incroyable, les LLM ne comprennent pas toujours correctement vos instructions. Et lorsque vous faites des dizaines, des centaines ou des milliers de requ√™tes, il y a toujours une chance qu'ils renvoient quelque chose d'inattendu.

C'est pourquoi les tests sont importants.

Dans le code ci-dessous, nous utilisons un `test` (une simple fonction) pour v√©rifier si la cat√©gorie renvoy√©e pour chaque entr√©e correspond aux cat√©gories attendues.

S'il y a une cat√©gorie inattendue, nous lan√ßons une erreur, et avec l'option `retry`, nous sp√©cifions que nous voulons r√©essayer cinq fois avant d'abandonner et de tout arr√™ter.

```ts showLineNumbers filename="sda/main.ts" {21-29}
import "@std/dotenv/load";
import { SimpleDB } from "@nshiab/simple-data-analysis";

const sdb = new SimpleDB({ logDuration: true });

const data = sdb.newTable("data");
await data.cache(async () => {
  await data.loadData(
    "https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv",
  );
});

await data.aiRowByRow(
  "payee",
  "categoryAI",
  `Categorize the payee into one of the following categories: Restaurant, Bar, Hotel or Other. `,
  {
    batchSize: 17,
    concurrent: 15,
    cache: true,
    test: (dataPoint) => {
      if (typeof dataPoint !== "string") {
        throw new Error("Not a string");
      }
      if (!["Restaurant", "Bar", "Hotel", "Other"].includes(dataPoint)) {
        throw new Error("Unexpected category");
      }
    },
    retry: 5,
    rateLimitPerMinute: 30,
    verbose: true,
  },
);

await data.logTable();

await sdb.done();
```

De mon c√¥t√©, aucune erreur n'a √©t√© g√©n√©r√©e. √áa a l'air bon !

![Test des r√©sultats.](/assets/simple-data-analysis/sda-and-ai/testing.png)

### Pr√©cision

Puisque nous avons test√© les r√©sultats, nous savons que nous avons les bonnes cat√©gories, mais ont-elles √©t√© correctement attribu√©es ?

Il est temps de v√©rifier la pr√©cision du mod√®le !

Puisque Ben a d√©j√† class√© les entreprises dans la colonne `category` et que nous avons mis les r√©sultats de l'IA dans la colonne `categoryAI`, utilisons quelques m√©thodes de SDA pour ce faire !

Premi√®rement, cr√©ons une nouvelle colonne pour v√©rifier si l'IA a retourn√© la bonne r√©ponse, en supposant que Ben avait raison.

En utilisant cette colonne, nous pouvons ensuite enregistrer toutes les occurrences de r√©ponses diff√©rentes entre Ben et l'IA.

Nous pouvons √©galement calculer la proportion de r√©ponses correctes de l'IA.

```ts showLineNumbers filename="sda/main.ts" {35-45}
import "@std/dotenv/load";
import { SimpleDB } from "@nshiab/simple-data-analysis";

const sdb = new SimpleDB({ logDuration: true });

const data = sdb.newTable("data");
await data.cache(async () => {
  await data.loadData(
    "https://raw.githubusercontent.com/palewire/first-llm-classifier/refs/heads/main/_notebooks/sample.csv",
  );
});

await data.aiRowByRow(
  "payee",
  "categoryAI",
  `Categorize the payee into one of the following categories: Restaurant, Bar, Hotel or Other. `,
  {
    batchSize: 17,
    concurrent: 15,
    cache: true,
    test: (dataPoint) => {
      if (typeof dataPoint !== "string") {
        throw new Error("Not a string");
      }
      if (!["Restaurant", "Bar", "Hotel", "Other"].includes(dataPoint)) {
        throw new Error("Unexpected category");
      }
    },
    retry: 5,
    rateLimitPerMinute: 30,
    verbose: true,
  },
);

await data.addColumn("correctCategory", "boolean", `category === categoryAI`);
await data.logTable({
  conditions: `correctCategory === false`,
  nbRowsToLog: "all",
});

await data.summarize({
  categories: "correctCategory",
});
await data.proportionsVertical("count", "perc");
await data.logTable();

await sdb.done();
```

Et... voici le r√©sultat !

Si nous v√©rifions les lignes avec des r√©ponses diff√©rentes entre Ben et l'IA, nous pouvons remarquer que... Ben a fait quelques erreurs !

Par exemple, *El POLLO INKA* et *ELLA DINNING ROOM* devraient √™tre des restaurants. Et *FAIRMONT BATTERY WHARF* devrait √™tre un h√¥tel. (Si vous ne voyez pas ces erreurs, c'est peut-√™tre parce que Ben les a corrig√©es !)

Pour le reste, comme nous n'avons pas les adresses, nous accorderons √† Ben le b√©n√©fice du doute.

Cela signifie que le mod√®le a atteint un taux de pr√©cision sup√©rieur √† 94 % ! Pas mal compte tenu de la simplicit√© de nos instructions et de la rapidit√© de traitement.

Selon ce sur quoi vous travaillez, peut-√™tre que ce niveau de pr√©cision est suffisant si vous le divulguez dans votre publication. Une chose est certaine : le faire √† la main aurait √©t√© beaucoup plus lent (ou tout simplement impossible s'il y avait des millions de lignes), et vous auriez √©galement fait des erreurs !

Si vous n'√™tes pas satisfait de la pr√©cision, vous pouvez affiner votre prompt, donner des exemples dans vos instructions, pr√©traiter les donn√©es ou simplement passer √† un autre mod√®le. Mais au moins, en v√©rifiant la pr√©cision, vous ne ferez pas de changements √† l'aveugle ! Vous saurez quand les choses s'am√©liorent et quand elles s'aggravent.

![Calcul du taux de pr√©cision.](/assets/simple-data-analysis/sda-and-ai/accuracy.png)

## Conclusion

Ici, nous avons classifi√© des donn√©es avec un mod√®le Gemini. Mais vous pouvez faire bien plus que cela, comme nettoyer, formater et extraire des donn√©es avec des LLM !

Et en utilisant la m√©thode `aiRowByRow` de SDA, vous pouvez le faire facilement, en quelques lignes de code, √† grande √©chelle !

Si vous avez des donn√©es sensibles que vous ne voulez pas envoyer √† Google ou √† un autre fournisseur d'IA, vous pouvez √©galement utiliser [Ollama](https://ollama.com/). Il suffit de le d√©marrer et de passer les variables suivantes dans votre fichier `.env`. SDA basculera automatiquement vers l'utilisation du mod√®le local install√© sur votre machine pour traiter les donn√©es.

```txt showLineNumbers filename="sda/main.ts"
OLLAMA=true
AI_MODEL=gemma3:4b
```

Parfois, les mod√®les open-source l√©gers ont plus de difficult√© √† renvoyer directement des listes (ce qui est la r√©ponse attendue pour `aiRowByRow`). Si c'est le cas, j'ai impl√©ment√© l'option `clean` qui vous permet de modifier directement la r√©ponse du LLM, par exemple en la restructurant en une liste.

Bien qu'il s'agisse d'une technologie exceptionnelle, n'oubliez pas que les r√©sultats ne sont pas garantis avec les LLM. Et, dans mes projets, plus les lots sont grands, plus les r√©sultats ont tendance √† √™tre mauvais...

Mais malgr√© tout, ils peuvent consid√©rablement acc√©l√©rer vos recherches et vos analyses. Ils sont incroyablement rapides et faciles √† utiliser.

Alors, si vous les essayez dans l'un de vos projets, [faites-le moi savoir](/contact) !

Et merci encore √† [Ben Welsh](https://github.com/palewire) et [Derek Willis](https://thescoop.org/about/) qui ont cr√©√© la version initiale de ce tutoriel.

<NoticeEnd lang="fr" />
